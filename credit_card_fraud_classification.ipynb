{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Classification - Toby Liang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Import Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays and dataframes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Introducing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         v8        v9  ...       v21       v22       v23       v24       v25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        v26       v27       v28  amount  label  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "path = \"./data/credit_card.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# Renaming columns\n",
    "columns = [\"time\"]\n",
    "for i in range(1, 29):\n",
    "    columns.append(\"v\" + str(i))\n",
    "for col in [\"amount\", \"label\"]:\n",
    "    columns.append(col)\n",
    "dataset.columns = columns\n",
    "\n",
    "# Printing first 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 284,807 examples with 31 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time      0\n",
       "v1        0\n",
       "v2        0\n",
       "v3        0\n",
       "v4        0\n",
       "v5        0\n",
       "v6        0\n",
       "v7        0\n",
       "v8        0\n",
       "v9        0\n",
       "v10       0\n",
       "v11       0\n",
       "v12       0\n",
       "v13       0\n",
       "v14       0\n",
       "v15       0\n",
       "v16       0\n",
       "v17       0\n",
       "v18       0\n",
       "v19       0\n",
       "v20       0\n",
       "v21       0\n",
       "v22       0\n",
       "v23       0\n",
       "v24       0\n",
       "v25       0\n",
       "v26       0\n",
       "v27       0\n",
       "v28       0\n",
       "amount    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for NaN values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No examples have NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time           2\n",
       "v1             0\n",
       "v2             0\n",
       "v3             0\n",
       "v4             0\n",
       "v5             0\n",
       "v6             0\n",
       "v7             0\n",
       "v8             0\n",
       "v9             0\n",
       "v10            0\n",
       "v11            0\n",
       "v12            0\n",
       "v13            0\n",
       "v14            0\n",
       "v15            0\n",
       "v16            0\n",
       "v17            0\n",
       "v18            0\n",
       "v19            0\n",
       "v20            0\n",
       "v21            0\n",
       "v22            0\n",
       "v23            0\n",
       "v24            0\n",
       "v25            0\n",
       "v26            0\n",
       "v27            0\n",
       "v28            0\n",
       "amount      1808\n",
       "label     283253\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for 0 values\n",
    "(dataset == 0).astype(int).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only features that have zero values are time and amount.  Time is the amount of time in seconds after the first transaction which can be zero if the transactions occur at the same time.  Amount is the amount of money involved in a transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count entries that have a 0 value for amount and is fraudulent\n",
    "((dataset.amount==0).astype(int) & (dataset.label==1)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27 entries have a 0 transaction amount and is fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    283726\n",
       "True       1081\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicate rows\n",
    "dataset.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1081 duplicate rows in the dataset.  These duplicates will have to be dropped in the data preprocessing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for number of unique labels\n",
    "dataset[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two unique labels in the dataset, meaning that this is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting labels\n",
    "dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many more non-fraudulent transactions than fraudulent transactions.  Thus, this is an imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop duplicates (Do not want duplicates in test set)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "\n",
    "# Duplicate drop sanity check\n",
    "print(\"Duplicates:\" + str((dataset.duplicated() == True).sum()))\n",
    "\n",
    "# Remove entries that have 0 amount?\n",
    "pass\n",
    "\n",
    "# Split features and labels\n",
    "features = dataset.drop(\"label\", axis=1)\n",
    "labels = dataset[[\"label\"]]\n",
    "\n",
    "# Standardize data\n",
    "features[features.columns] = scale(features[features.columns])\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    283253\n",
      "1       473\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(            time         v1         v2         v3        v4         v5  \\\n",
       " 267691  1.433626  -0.004541  -0.365371   0.686368 -1.519851  -0.234126   \n",
       " 53820  -1.024581   0.620644  -0.053318   0.223415 -0.160467  -0.305759   \n",
       " 177193  0.595311  -0.014273   0.473474  -1.150959 -0.131520   0.404182   \n",
       " 113527 -0.457280  -0.335202   0.726371   1.283372  0.405577   0.063191   \n",
       " 128136 -0.341191   0.627215   0.438639  -0.057072  1.472987   0.586397   \n",
       " 222897  1.018428  -0.800649  -0.238016  -0.623366 -0.221571   0.549546   \n",
       " 276636  1.524946   0.949680  -1.171623  -0.820587 -1.317934   0.366838   \n",
       " 12461  -1.536554  -0.374760   0.240223   1.853330 -1.181649  -0.289775   \n",
       " 159016  0.364186  -0.718619   0.139712   0.983762 -0.662134   0.818117   \n",
       " 126031 -0.356081   0.588598   0.066925  -0.227643  0.704031   0.114647   \n",
       " 88929  -0.683644   0.581910  -1.106500   0.785327 -0.816525  -1.795504   \n",
       " 216996  0.966933   0.918158  -0.207132  -0.621660  1.222141   0.175657   \n",
       " 172405  0.553420   1.077877   0.118580  -1.273940  0.194846   0.569625   \n",
       " 127693 -0.345024   0.590203   0.165057   0.254548  0.408302  -0.158767   \n",
       " 149252 -0.082519   1.046190  -0.037218  -0.700537  0.311997   0.042482   \n",
       " 195344  0.762409   1.097248  -0.484681  -0.968423 -0.678613  -0.277355   \n",
       " 104077 -0.545673   0.681807  -0.479663  -1.132631 -1.259272   1.273319   \n",
       " 202470  0.832648  -0.192612   0.643741  -1.687529 -1.503041   2.391263   \n",
       " 23610  -1.305156  -0.635861   0.501181   1.135567  0.749841   0.075526   \n",
       " 92560  -0.649125   0.672797  -0.373261   0.378280 -0.524116  -0.776008   \n",
       " 30593  -1.238688  -0.455315   0.610105   0.976695  0.884070   0.197099   \n",
       " 3811   -1.926753  -0.480956   0.651904   1.418985  1.043078   0.802696   \n",
       " 49083  -1.072158   0.602774   0.207657   0.293614  0.972680  -0.007693   \n",
       " 20893  -1.336790  -0.219934   0.867927   1.104554  1.619401   0.366818   \n",
       " 82333  -0.746596  -0.938884  -0.023125   1.382237 -0.422008  -0.369088   \n",
       " 218719  0.981887  -0.254841   0.425668   0.869877 -0.563903  -0.108624   \n",
       " 47333  -1.087511  -1.455066   1.155287   0.511752  0.155254  -0.896907   \n",
       " 158726  0.355362   1.066212  -0.000610  -1.011264  0.155219   0.244066   \n",
       " 214007  0.941007   1.112465   0.061351  -1.661897 -0.115918   0.695933   \n",
       " 84192  -0.728946  -0.594171   0.402717   1.126265  0.230953  -0.317814   \n",
       " ...          ...        ...        ...        ...       ...        ...   \n",
       " 249167  1.252437  -0.824492  -2.115744  -4.282498  2.297995  -1.173877   \n",
       " 154371  0.136937 -13.260574  11.642299 -16.830511  7.869146 -12.116486   \n",
       " 150684 -0.019441  -5.157306   3.730684  -8.599962  5.475621  -6.308275   \n",
       " 8617   -1.751777   0.468793   2.552843  -4.995906  5.253856   0.810736   \n",
       " 68320  -0.881976   0.529112   0.249810   0.501162  2.237894  -0.413905   \n",
       " 15476  -1.431059 -10.890549   7.685875 -15.613356  4.367929 -11.640100   \n",
       " 18773  -1.370193   0.135366   2.158189  -3.852354  4.110035   1.116176   \n",
       " 77348  -0.796194  -0.655619   1.498032  -1.891063  1.645790  -0.997870   \n",
       " 6719   -1.819594  -0.132128   2.622006  -4.568931  4.808267   0.446236   \n",
       " 6529   -1.830630  -0.816942   1.983190  -2.743482  1.668854  -1.021688   \n",
       " 8845   -1.742089  -2.429966   1.851341  -3.711834  4.194056  -1.592293   \n",
       " 64329  -0.920349  -5.058818   4.475424  -8.550626  3.023862  -5.529257   \n",
       " 45203  -1.107056  -1.298716   1.276666  -3.279483  4.567698   2.303617   \n",
       " 18773  -1.370193   0.135366   2.158189  -3.852354  4.110035   1.116176   \n",
       " 125342 -0.361915  -3.667810   1.686534  -4.480381  3.146288  -3.969668   \n",
       " 140786 -0.229083  -0.225428   1.477205  -2.650045  3.446704  -1.305830   \n",
       " 268375  1.439944  -2.692333   0.380851  -3.835222  1.189278  -0.265982   \n",
       " 8842   -1.742131  -2.414095   1.638430  -2.967328  3.868422  -1.131866   \n",
       " 41395  -1.140438  -2.285786  -0.006473  -3.398947  4.913157   3.825276   \n",
       " 251891  1.279185   0.961135   0.807533  -1.547766  2.995455   0.982825   \n",
       " 234705  1.121774  -1.142253   0.444505  -3.618955  4.191694   2.854480   \n",
       " 262826  1.386954  -0.217275   2.856738  -4.986733  5.427062   0.188085   \n",
       " 76609  -0.803713  -4.500975   1.697434  -5.093448  4.945744  -3.799928   \n",
       " 88307  -0.689352  -0.824105   1.586114  -1.981075  2.168832  -1.815346   \n",
       " 230476  1.085339  -0.054230   1.700097  -4.259002  2.298488  -1.186718   \n",
       " 88876  -0.684086   0.582615   0.744187  -0.964134  1.464127   0.619398   \n",
       " 30384  -1.240752  -1.469740   2.459304  -2.783171  3.882221  -2.231366   \n",
       " 230476  1.085339  -0.054230   1.700097  -4.259002  2.298488  -1.186718   \n",
       " 6446   -1.835242   0.357692   1.476023  -3.470669  3.125219  -1.577796   \n",
       " 154697  0.164570  -2.169963   1.746071  -3.904295  4.874847  -2.474007   \n",
       " \n",
       "               v6         v7         v8         v9  ...        v20        v21  \\\n",
       " 267691  0.369447   0.031292   0.037549  -0.613231  ...   0.422743   0.595223   \n",
       " 53820  -0.277406  -0.196580   0.068252   0.062784  ...  -0.163205  -0.051388   \n",
       " 177193 -0.227580   0.986663   0.095925  -0.367125  ...   0.367572   0.532775   \n",
       " 113527 -0.043873   0.429568   0.171455  -0.697519  ...   0.212108  -0.343332   \n",
       " 128136  0.187977   0.365546  -0.054454  -1.234413  ...  -0.024218  -0.538106   \n",
       " 222897 -0.644584   0.554802   0.371524   0.230439  ...   0.841234  -0.066934   \n",
       " 276636  3.127757  -1.718758   0.975013   0.405403  ...  -0.288061  -0.150484   \n",
       " 12461  -0.287846   0.274866  -0.094168   2.354168  ...  -0.162119  -0.153904   \n",
       " 159016 -0.480178   0.387788   0.032843  -0.359387  ...  -0.270831  -0.021867   \n",
       " 126031 -0.427263   0.361658  -0.195026  -0.019117  ...   0.028340  -0.052925   \n",
       " 88929  -0.320281  -1.261104   0.005530  -1.073705  ...   0.007954   0.234630   \n",
       " 216996  0.236670  -0.012235  -0.044277  -0.486798  ...   0.258542  -0.729725   \n",
       " 172405 -0.345218   0.171261  -0.185462   0.377948  ...  -0.122738  -0.532932   \n",
       " 127693 -0.293280  -0.068590   0.054131  -0.236338  ...  -0.131395  -0.266969   \n",
       " 149252 -0.510755  -0.067701  -0.164388   1.581457  ...  -0.397693  -0.579350   \n",
       " 195344 -0.664957  -0.220526  -0.219188  -0.646108  ...   0.028191   0.102924   \n",
       " 104077  2.197963  -0.434482   0.518459  -1.165827  ...   0.462069  -0.203507   \n",
       " 202470  2.026741   0.581250   0.879816  -0.657357  ...  -0.146778   0.395367   \n",
       " 23610   0.031650   0.381296   0.148765  -0.637080  ...   0.049531   0.231389   \n",
       " 92560  -0.261416  -0.590796  -0.025943  -0.905248  ...  -0.466735  -0.452519   \n",
       " 30593   1.873240  -0.965521  -1.750016  -0.043532  ...   0.912020  -2.196506   \n",
       " 3811    1.491700   0.285871   0.671934  -1.505368  ...  -0.275806  -0.039724   \n",
       " 49083  -0.110115   0.127178  -0.081194   0.064903  ...  -0.144731  -0.123009   \n",
       " 20893  -0.543814   1.097234  -0.394196  -1.445362  ...   0.053091   0.011413   \n",
       " 82333  -0.622254  -0.344668   0.519015   0.156955  ...   0.420515   0.294593   \n",
       " 218719  0.455939  -0.369542   0.600320   0.189523  ...  -0.130440  -0.001987   \n",
       " 47333  -0.627401  -0.143483   0.640962   0.106372  ...  -0.609982  -0.080119   \n",
       " 158726 -0.588386   0.162069  -0.245114   0.508986  ...  -0.260543   0.331901   \n",
       " 214007 -0.917506   0.695651  -0.502065   0.175772  ...  -0.185142   0.133619   \n",
       " 84192  -0.557455   0.922077  -0.209601  -0.244399  ...  -0.444749   0.026974   \n",
       " ...          ...        ...        ...        ...  ...        ...        ...   \n",
       " 249167 -0.945423   0.233307  -0.040804  -0.669452  ...   4.141868   1.645990   \n",
       " 154371  2.954242 -30.189189 -24.391576 -10.155293  ...  10.269307 -23.375406   \n",
       " 150684 -2.880253  -9.700964   4.948150  -5.230039  ...  -0.107096   3.900774   \n",
       " 8617   -2.166470  -1.093817   0.309391  -2.009719  ...   0.695142   0.437161   \n",
       " 68320   0.152651  -0.563351   0.349632   0.308871  ...  -0.285264  -0.068706   \n",
       " 15476  -3.319289 -13.221268  11.973053  -3.579351  ...   2.080893   2.429605   \n",
       " 18773  -1.702854  -0.672827   0.298481  -3.429937  ...   0.403045   0.513175   \n",
       " 77348  -0.711041  -2.498274   0.990441  -2.069552  ...   0.727667   0.902479   \n",
       " 6719   -2.226236  -1.986258   0.415743  -3.076286  ...   0.821476   0.742170   \n",
       " 6529   -1.410209  -2.863564   1.286170  -1.100484  ...   0.410100   0.693339   \n",
       " 8845   -1.147347  -3.656726   0.777952  -1.191625  ...  -0.270067   0.899781   \n",
       " 64329  -2.572140  -6.803673   5.822013  -2.177993  ...   1.080817   1.287911   \n",
       " 45203  -2.295669  -0.151923  -0.330406  -3.330212  ...  -0.211673   0.039101   \n",
       " 18773  -1.702854  -0.672827   0.298481  -3.429937  ...   0.403045   0.513175   \n",
       " 125342 -1.285551  -5.284164   2.892365  -2.785872  ...  -0.801494   1.800810   \n",
       " 140786 -0.439760  -3.792855   1.090778  -2.502936  ...   0.967349   0.986216   \n",
       " 268375 -0.357493  -3.484618  -0.588878  -2.711158  ...  -0.264236  -0.450015   \n",
       " 8842   -1.162436  -3.344582   0.470538  -1.366394  ...  -0.206703   0.793289   \n",
       " 41395  -3.225427  -2.112180   0.291357  -3.540940  ...  -0.140514   0.342976   \n",
       " 251891 -0.639951   0.581776  -0.139142  -1.369933  ...  -0.293896  -0.209640   \n",
       " 234705 -2.316074  -1.368187   0.734428  -2.898851  ...   1.252735   0.577204   \n",
       " 262826 -1.986258  -2.326563   0.813906  -4.187110  ...   1.080346   0.860014   \n",
       " 76609  -0.267468  -7.890954   1.484403  -4.102347  ...  -0.598165  -0.124541   \n",
       " 88307  -0.405400  -1.856853   1.076306  -1.821773  ...   0.292404   0.916282   \n",
       " 230476 -2.076332  -1.884903   0.815798  -1.729275  ...   0.442492   0.895259   \n",
       " 88876  -0.735838   0.263846  -0.031268   0.104807  ...  -0.088183  -0.521097   \n",
       " 30384  -1.067285  -4.604782   1.713674  -4.576849  ...   1.274602   1.492860   \n",
       " 230476 -2.076332  -1.884903   0.815798  -1.729275  ...   0.442492   0.895259   \n",
       " 6446   -2.001920  -3.160389   0.773665  -0.150255  ...   0.548786   0.761907   \n",
       " 154697 -0.865853  -6.306076   2.419076  -2.287535  ...  -0.296200   2.239182   \n",
       " \n",
       "              v22       v23       v24       v25       v26        v27       v28  \\\n",
       " 267691  1.506592 -0.161098  0.316046  0.202942 -0.225549  -0.505519 -0.752922   \n",
       " 53820  -0.158581  0.112163  0.125800  0.232509  2.021039  -0.192383 -0.035891   \n",
       " 177193  1.158578  0.386725 -0.050698 -0.060677 -0.311133  -0.319204 -0.091185   \n",
       " 113527 -0.958888 -0.307197 -0.092637  0.322145 -1.115814   0.818681  0.405702   \n",
       " 128136 -1.679450 -0.025737 -1.446842  0.929337 -0.613086  -0.080176  0.009519   \n",
       " 222897 -1.056300  0.506060  0.523548  0.757777 -0.195970   0.122114 -0.444758   \n",
       " 276636 -0.062086  0.472866  1.239303 -1.569855  2.604604  -0.055021 -0.078793   \n",
       " 12461   0.340579 -0.475593  0.570240  0.650980 -1.726105  -0.177349 -0.467321   \n",
       " 159016 -0.134787 -0.868464 -0.500836  1.266338  0.537113  -0.248626  0.056801   \n",
       " 126031 -0.378135 -0.427713 -0.749966  1.526454 -0.651355  -0.045713  0.065541   \n",
       " 88929   0.720051 -0.226746  0.651364  0.245554 -0.119881   0.120063  0.200248   \n",
       " 216996 -2.622699  0.750672  0.087312 -1.931313  3.369423  -0.545040 -0.123749   \n",
       " 172405 -1.323824  0.430534 -0.080023 -0.331359  0.432209  -0.143842 -0.108208   \n",
       " 127693 -0.769176  0.272409  0.308133  0.172169  0.194067  -0.028466  0.057923   \n",
       " 149252 -1.254169  0.498548 -0.698339 -0.653412  0.337457  -0.277048 -0.250898   \n",
       " 195344  0.211983  0.185106 -0.538266 -0.024025 -0.584490  -0.131148 -0.220046   \n",
       " 104077 -1.226942 -0.058874  1.635068  1.115556 -0.922616  -0.094605  0.053774   \n",
       " 202470  1.086260 -0.253034  1.245179 -0.477982  0.230872   0.727862  0.602326   \n",
       " 23610   0.760846 -0.456308  0.371876  0.668080 -0.210205   0.214360  0.569014   \n",
       " 92560  -0.690267  0.044179  0.062922  0.220958  2.051091  -0.113608  0.017994   \n",
       " 30593  -0.007977  0.090304 -2.195318 -0.494581 -0.806079   0.548053  0.488732   \n",
       " 3811   -0.230663 -0.038346 -1.798342 -0.408563 -0.248822   0.230061  0.154381   \n",
       " 49083   0.093488 -0.117453  0.222020  1.373383 -0.657791   0.124088  0.052919   \n",
       " 20893   0.128328 -0.555172  1.175577  1.042829  0.299345  -0.861702 -0.757146   \n",
       " 82333   0.438277 -0.298366  0.767750  0.609357  2.167550   0.253013 -0.200023   \n",
       " 218719 -0.121125 -0.387772  0.102010  1.075197  1.085777  -0.689526 -0.693151   \n",
       " 47333  -0.562357  0.006256  1.189313  0.656897  0.383360  -3.364377 -0.852241   \n",
       " 158726  1.155726  0.036485  1.065302  0.569812 -0.275409  -0.055545 -0.162629   \n",
       " 214007  0.583354 -0.307939 -1.533570  1.131322  0.620334  -0.224360 -0.261378   \n",
       " 84192   0.090000 -0.136131  1.135502 -0.448894 -1.470814  -0.082671  0.441776   \n",
       " ...          ...       ...       ...       ...       ...        ...       ...   \n",
       " 249167 -1.334797 -2.346666 -1.031074 -0.338109  0.830198   0.382025  1.454847   \n",
       " 154371  7.872066  5.627407  0.089356 -1.288806 -0.434768 -12.512622 -1.368672   \n",
       " 150684  1.591362 -0.909956  1.391615  1.055544  0.235955  -0.781158  0.186215   \n",
       " 8617    0.076177  0.337492 -0.690413 -1.747740  0.967477   1.580900  0.479547   \n",
       " 68320   0.170831 -0.212868  0.577942  0.974511  0.393052   0.149725  0.190820   \n",
       " 15476  -2.101408 -1.449505  0.214575  2.791701 -0.463360   3.914573  1.405109   \n",
       " 18773  -0.444793 -0.881919 -0.860008  2.644650  1.171170   1.393560  1.225063   \n",
       " 77348   0.113099 -0.355212 -0.864885  0.430645  1.568679   1.594563  0.761037   \n",
       " 6719   -0.753725 -0.970717 -0.435843  2.954894  1.085825   2.247068  1.744354   \n",
       " 6529   -0.754750 -0.123107 -0.703016  0.237667  0.667636   0.662715  0.403228   \n",
       " 8845    0.351941  1.007927 -0.393548 -1.287557 -0.069991  -3.369711  2.149678   \n",
       " 64329  -1.206892 -0.309183 -0.058849  1.033917 -0.547831   2.861280  0.687219   \n",
       " 45203   0.304164  1.565092 -0.480088  2.227918  1.377038   1.147865 -1.238406   \n",
       " 18773  -0.444793 -0.881919 -0.860008  2.644650  1.171170   1.393560  1.225063   \n",
       " 125342 -0.022225 -1.405910  0.630778 -2.022932 -1.275288  -1.942197  1.246476   \n",
       " 140786 -0.564404 -0.514810 -1.328287  1.847752  0.413666   2.761311  1.648041   \n",
       " 268375  2.083025 -0.346583 -0.406094  1.713815  1.795675   2.155170 -2.941930   \n",
       " 8842   -0.110617  0.510196 -0.406318  0.649383  0.066634  -3.816164  1.852071   \n",
       " 41395  -0.068417 -0.362698 -0.662868  1.642986  1.371476   1.240190  2.961006   \n",
       " 251891 -0.497856  0.069290 -0.400567  0.328710 -0.005706  -0.071839  0.014299   \n",
       " 234705 -1.128051 -0.046417  0.042119 -1.583984 -0.027463   1.039887 -0.402208   \n",
       " 262826 -0.604091 -0.145192 -1.226858 -0.598842  1.042264   2.071109  1.133543   \n",
       " 76609   0.481133  0.081664 -0.686305  0.421891  0.684306  -0.075844 -0.478064   \n",
       " 88307   0.254092 -0.143739 -0.835853 -0.119003 -0.109664   0.811362  0.410700   \n",
       " 230476  0.174717  0.326687  0.013673 -0.334348  1.193119   0.381846 -0.300952   \n",
       " 88876  -1.095087 -0.212492 -0.547864  1.276066 -0.641968   0.248087  0.373266   \n",
       " 30384  -0.774784  0.164310 -0.111305 -0.914584 -0.215466   2.944330  2.021439   \n",
       " 230476  0.174717  0.326687  0.013673 -0.334348  1.193119   0.381846 -0.300952   \n",
       " 6446   -0.013508  1.156804  0.781063 -3.758631  0.662431   1.512905  0.392523   \n",
       " 154697  2.164052 -0.927055 -0.097848 -3.508957 -0.150561   0.341058 -1.830327   \n",
       " \n",
       "           amount  \n",
       " 267691  0.046036  \n",
       " 53820  -0.347496  \n",
       " 177193  0.379064  \n",
       " 113527 -0.352848  \n",
       " 128136 -0.293063  \n",
       " 222897  0.463210  \n",
       " 276636  0.153464  \n",
       " 12461  -0.306002  \n",
       " 159016 -0.273854  \n",
       " 126031 -0.000690  \n",
       " 88929   0.361532  \n",
       " 216996  0.216124  \n",
       " 172405 -0.346178  \n",
       " 127693 -0.345419  \n",
       " 149252 -0.345419  \n",
       " 195344 -0.188031  \n",
       " 104077  0.026068  \n",
       " 202470 -0.341386  \n",
       " 23610  -0.137671  \n",
       " 92560  -0.242104  \n",
       " 30593  -0.306641  \n",
       " 3811   -0.331482  \n",
       " 49083  -0.349333  \n",
       " 20893  -0.283279  \n",
       " 82333  -0.153646  \n",
       " 218719 -0.347376  \n",
       " 47333  -0.276569  \n",
       " 158726 -0.343383  \n",
       " 214007 -0.270539  \n",
       " 84192   0.245717  \n",
       " ...          ...  \n",
       " 249167  5.656801  \n",
       " 154371 -0.344221  \n",
       " 150684 -0.349333  \n",
       " 8617   -0.349333  \n",
       " 68320  -0.350292  \n",
       " 15476   0.045996  \n",
       " 18773  -0.350611  \n",
       " 77348  -0.353287  \n",
       " 6719   -0.349333  \n",
       " 6529   -0.349333  \n",
       " 8845   -0.231961  \n",
       " 64329   0.045996  \n",
       " 45203  -0.349333  \n",
       " 18773  -0.350611  \n",
       " 125342  0.073592  \n",
       " 140786 -0.349333  \n",
       " 268375 -0.193662  \n",
       " 8842   -0.353327  \n",
       " 41395  -0.349333  \n",
       " 251891 -0.325132  \n",
       " 234705 -0.353327  \n",
       " 262826 -0.350252  \n",
       " 76609  -0.323295  \n",
       " 88307   0.365526  \n",
       " 230476  0.025349  \n",
       " 88876  -0.349333  \n",
       " 30384  -0.349333  \n",
       " 230476  0.025349  \n",
       " 6446   -0.349333  \n",
       " 154697 -0.323015  \n",
       " \n",
       " [509874 rows x 30 columns],         label\n",
       " 267691      0\n",
       " 53820       0\n",
       " 177193      0\n",
       " 113527      0\n",
       " 128136      0\n",
       " 222897      0\n",
       " 276636      0\n",
       " 12461       0\n",
       " 159016      0\n",
       " 126031      0\n",
       " 88929       0\n",
       " 216996      0\n",
       " 172405      0\n",
       " 127693      0\n",
       " 149252      0\n",
       " 195344      0\n",
       " 104077      0\n",
       " 202470      0\n",
       " 23610       0\n",
       " 92560       0\n",
       " 30593       0\n",
       " 3811        0\n",
       " 49083       0\n",
       " 20893       0\n",
       " 82333       0\n",
       " 218719      0\n",
       " 47333       0\n",
       " 158726      0\n",
       " 214007      0\n",
       " 84192       0\n",
       " ...       ...\n",
       " 249167      1\n",
       " 154371      1\n",
       " 150684      1\n",
       " 8617        1\n",
       " 68320       1\n",
       " 15476       1\n",
       " 18773       1\n",
       " 77348       1\n",
       " 6719        1\n",
       " 6529        1\n",
       " 8845        1\n",
       " 64329       1\n",
       " 45203       1\n",
       " 18773       1\n",
       " 125342      1\n",
       " 140786      1\n",
       " 268375      1\n",
       " 8842        1\n",
       " 41395       1\n",
       " 251891      1\n",
       " 234705      1\n",
       " 262826      1\n",
       " 76609       1\n",
       " 88307       1\n",
       " 230476      1\n",
       " 88876       1\n",
       " 30384       1\n",
       " 230476      1\n",
       " 6446        1\n",
       " 154697      1\n",
       " \n",
       " [509874 rows x 1 columns])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def oversample(train_features, train_labels):\n",
    "    # Concatenate features and labels for train set\n",
    "    train_dataset = pd.concat([train_features, train_labels], axis = 1)\n",
    "    \n",
    "    # Get non_fraud and fraud data\n",
    "    not_fraud_dataset = train_dataset[train_dataset.label == 0]\n",
    "    fraud_dataset = train_dataset[train_dataset.label == 1]\n",
    "    \n",
    "    # Oversample fraud\n",
    "    fraud_oversampled = resample(fraud_dataset, replace = True, n_samples = len(not_fraud_dataset))\n",
    "    \n",
    "    # Oversampled data\n",
    "    train_dataset_oversampled = pd.concat([not_fraud_dataset, fraud_oversampled])\n",
    "    \n",
    "    # Split features and labels\n",
    "    train_features_oversampled = train_dataset_oversampled.drop(\"label\", axis=1)\n",
    "    train_labels_oversampled = train_dataset_oversampled[[\"label\"]]\n",
    "    \n",
    "    # Sanity check\n",
    "    print(labels[\"label\"].value_counts())\n",
    "    \n",
    "    return (train_features_oversampled, train_labels_oversampled)\n",
    "oversample(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
